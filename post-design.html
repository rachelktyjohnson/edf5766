<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>e-Semble - EDF5766</title>
    <link rel="stylesheet" href="./css/styles.css">
    <link rel="icon" type="image/png" href="favicon-32x32.png" sizes="32x32"/>
    <link rel="icon" type="image/png" href="favicon-16x16.png" sizes="16x16"/>

</head>
<body>
<div class="container">
    <header>
        <!-- header inputted by JS -->
    </header>
    <main>
        <aside>
            <div id="outline">
                <!-- outline inputted by JS -->
            </div>
        </aside>
        <article>
            <h1 id="post-design">Post Design</h1>
            <h2 id="iterate">Iterate</h2>
            <h3 id="post-program-reflection-and-empathy">Post Program Reflection and Empathy</h3>
            <p>
                In the immediate aftermath of our pilot run, we enter a reflective phase, akin to the initial Empathise stage. It's an opportunity to reconnect with students, guardians, and our team to gather their thoughts, feelings, and experiences during the trial program. Just as in Empathise, this post-program reflection centres around understanding the participants' perspectives and challenges. By listening attentively and empathetically, we aim to identify their unique journeys through the program and uncover any underlying motivations, hesitations, or suggestions.
            </p>
            <p>
                Through similar methods in the Empathise stage, we aim to gain a more profound understanding of our students' responses to the hybrid ensemble program, the impact on their motivation and practice habits, and the effectiveness of our teaching materials. The goal is to capture the authentic voices of our students and their guardians, much like we did during the early stages of our program's development.
            </p>
            <h3 id="analysing-and-assessing">Analysing and assessing</h3>
            <p>
                We will then engage in a thorough analysis of the data collected during the post-program reflection and feedback sessions. Similar UX tools used in the Define stage will be revisited. This analysis is essential in shaping the next steps of our hybrid ensemble initiative and fine-tuning its components.
            </p>
            <h4>Assessment of Practice Habits</h4>
            <p>
                We examine the data gathered from the Impact Assessment System to compare students' practice habits and motivation before and after their participation in the program. This assessment provides valuable insights into the program's effect on students' practice hours, engagement, and overall motivation, allowing us to gauge the impact accurately.
            </p>
            <h4>Performance Evaluation</h4>
            <p>
                We evaluate the musical output created by the students during the pilot program. This evaluation encompasses the quality of the performances, student engagement, and the impact on their motivation and skill development. By thoroughly assessing their musical progress, we gain a clearer picture of the program's educational and developmental impact.
            </p>
            <h4>Technical Assessment</h4>
            <p>
                A key component of our analysis focuses on the technical aspects of our program. We evaluate the usability of the technology integration that includes music notation software, audio/video post-production tools, and recording guidelines. This assessment helps us ensure that students can effectively use these tools, and we gather feedback regarding any technical issues or challenges they may have encountered.
            </p>
            <h4>Guardian Involvement Evaluation</h4>
            <p>
                Using the data collected through the Feedback Collection System, we assess the extent to which guardians were engaged and informed about their students' participation in the program. By gathering feedback from guardians, we gain insight into their perception of the program's educational and developmental aspects. Their input is vital in understanding how the program impacts students and their roles as supportive stakeholders.
            </p>
            <h4>Teacher Feedback</h4>
            <p>
                We gather their feedback teachers' experiences and observations during the pilot program. Teachers provide critical insights into student progress, engagement, and challenges they've observed. This firsthand perspective informs our understanding of the program's effectiveness in enhancing the music education experience.
            </p>
            <h3 id="refinement-and-iteration">Refinement and Iteration</h3>
            <p>
                As we transition into the refinement phase of our Hybrid Ensemble Program, we will capitalise on the insights gleaned from the assessment stage and the invaluable feedback collected. This wealth of information will be used to facilitate essential adjustments to the program. Every subsequent iteration of the program will undergo a similar structure of the Test and Post-Design stages, ensuring that our program remains in sync with the evolving needs and aspirations of our students.
            </p>
            <h2 id="launch">Launch</h2>
            <p>
                In Term 3, Week 1, we embark on an exciting journey as we officially launch our pilot program. This pivotal stage of our project marks the culmination of extensive planning and prototyping, bringing our innovative Hybrid Ensemble Program to life.
            </p>
            <p>
                Our focus during this launch week is twofold: to carefully execute the pilot program and to establish a robust feedback mechanism for ongoing refinement.
            </p>
            <h3 id="executing-the-pilot-program">Executing the Pilot Program</h3>
            <p>
                With a clear roadmap in hand, we execute the stakeholder-designed, user-tested wicked solution. This includes implementing lesson plans and materials designed by student, as well as adhering to the schedule crafted during the prototype stage. The technology guidelines and other resources come into play, ensuring a seamless experience for both students and teachers.
            </p>
            <h3 id="monitoring-progress">Monitoring Progress</h3>
            <p>
                As the program unfolds, we maintain a vigilant eye on its progress. Teachers play a crucial role in facilitating and guiding their students, ensuring that they adhere to the guidelines and actively engage in the program's activities. Admin continues to monitor, gather data, and refine subsequent iterations.
            </p>
            <h3 id="collecting-ongoing-feedback">Collecting Ongoing Feedback</h3>
            <p>
                In keeping with our commitment to continuous improvement, we institute an ongoing feedback system during the launch week. This includes regular check-ins with students, teachers, and guardians to understand their experiences and insights as they unfold. We encourage open communication channels, seeking valuable input that will guide us in making immediate adjustments when necessary.
            </p>
            <h3 id="laying-the-foundation-for-ongoing-iteration">Laying the Foundation for Ongoing Iteration</h3>
            <p>
                The launch of our pilot program is not a static event but rather the foundation for continuous iteration. We understand that innovation thrives on feedback and adaptation. With these insights, we are poised to refine our program throughout its duration, ensuring its alignment with the ever-evolving needs and aspirations of our students.
            </p>
        </article>

        <div id="back-to-top">
            <button id="top-button">â†‘</button>
        </div>
    </main>
    <footer>
        <!--footer inputted by JS-->
    </footer>
</div>

<script src="index.js"></script>
</body>
</html>